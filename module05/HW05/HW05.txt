UWID, City
kegedy, AnnArbor

1a) What is the output shape of the second Conv2D() layer?
Answer: (None, 24, 24, 32) 

>>> model.summary()
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 26, 26, 16)        160       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         
_________________________________________________________________
dropout (Dropout)            (None, 12, 12, 32)        0         
_________________________________________________________________
flatten (Flatten)            (None, 4608)              0         
_________________________________________________________________
dense (Dense)                (None, 128)               589952    
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 596,042
Trainable params: 596,042
Non-trainable params: 0


1b) How many parameters are there in the second Conv2D() layer?
Answer: 4640 parameters


1c) Assuming your model uses single precision (32-bit floating point numbers) for parameters, what will be the size of the second Conv2D() layer in bytes?
Answer: 4640 * 4 = 18560 bytes

1d) Why would the size of a model trained with optimizer="rmsprop" be about twice the size of the model trained with optimizer="sgd"?
Answer: Rmsprop has much larger weights compared to sgd.
